{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '../../common/Cluster')\n",
    "from plot_pie import plot_pie\n",
    "\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "from backup_outlier_detection_post_cluster import retirve_list_over_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **K-means, scoring when comparing with and without outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares k-means with six clusters before and after outlier removal, using silhouette_score, davies_bouldin_score and calinski_harabasz_score. The motivation for doing this is to analyze how big the effect of removing outlier net station is.\n",
    "<br>\n",
    "<br>\n",
    "Outliers are detected using the function retrive_list_over_outliers. Several metric to use to detect outliers in retrive_list_over_outliers was tested in outlier_removal_metric_comparison. This notebook can be found in common -> Results -> feature_clustering. It has also been tested to remove outliers with two and three layers of clustering, see notebook hierarchical_clustering_combinations_for_outlier_removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../parquet_files/weekly_load_all_trafos.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining k-means clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_t=df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "km1 = KMeans(n_clusters=6)\n",
    "\n",
    "y_km1 = km1.fit_predict(weekly_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=weekly_t.loc[y_km1 == 0].transpose()\n",
    "c2=weekly_t.loc[y_km1 == 1].transpose()\n",
    "c3=weekly_t.loc[y_km1 == 2].transpose()\n",
    "c4=weekly_t.loc[y_km1 == 3].transpose()\n",
    "c5=weekly_t.loc[y_km1 == 4].transpose()\n",
    "c6=weekly_t.loc[y_km1 == 5].transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means without outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_kmeans_raw = df.T.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list that matches net station id to which cluster (1-6) net station is placed in.\n",
    "#Used when computing score.\n",
    "\n",
    "label_kmeans_raw = []\n",
    "for idx in df.T.index:\n",
    "    if idx in list(c1.columns):\n",
    "        label_kmeans_raw.append(1)\n",
    "    elif idx in list(c2.columns):\n",
    "        label_kmeans_raw.append(2)\n",
    "    elif idx in list(c3.columns):\n",
    "        label_kmeans_raw.append(3)\n",
    "    elif idx in list(c4.columns):\n",
    "        label_kmeans_raw.append(4)\n",
    "    elif idx in list(c5.columns):\n",
    "        label_kmeans_raw.append(5)\n",
    "    elif idx in list(c6.columns):\n",
    "        label_kmeans_raw.append(6)\n",
    "    else:\n",
    "        print(\"ERROR: \", idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means with outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = (retirve_list_over_outliers(c1) + retirve_list_over_outliers(c2) +  \n",
    "            retirve_list_over_outliers(c3) + retirve_list_over_outliers(c4) +\n",
    "            retirve_list_over_outliers(c5) + retirve_list_over_outliers(c6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove net stations that have been detected as outliers\n",
    "df_outliers_removed = df.drop(outliers, axis=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_kmeans_outliers_removed = df_outliers_removed.T.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list that matches net station id to which cluster (1-6) net station is placed in. \n",
    "#Used when computing score.\n",
    "\n",
    "label_kmeans_outliers_removed = []\n",
    "for idx in df_outliers_removed.T.index:\n",
    "    if idx in list(c1.columns):\n",
    "        label_kmeans_outliers_removed.append(1)\n",
    "    elif idx in list(c2.columns):\n",
    "        label_kmeans_outliers_removed.append(2)\n",
    "    elif idx in list(c3.columns):\n",
    "        label_kmeans_outliers_removed.append(3)\n",
    "    elif idx in list(c4.columns):\n",
    "        label_kmeans_outliers_removed.append(4)\n",
    "    elif idx in list(c5.columns):\n",
    "        label_kmeans_outliers_removed.append(5)\n",
    "    elif idx in list(c6.columns):\n",
    "        label_kmeans_outliers_removed.append(6)\n",
    "    else:\n",
    "        print(\"ERROR: \", idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation, scoring**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See common -> Results -> data_driven_clustering -> datadriven_clustering_results for a detailed description of each scoring metric. Included here is a short summary to help understand the results. \n",
    "The text description used here does not comply with copyright rules, and must be changed/removed if to be published. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **silhouette_score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Silhouette score is a measure of how well samples are clustered with samples that are similar to themselves. Clustering models with a high Silhouette score are said to be dense, where samples in the same cluster are similar to each other, and well separated, where samples in different clusters are not very similar to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score_with_outliers = silhouette_score(x_kmeans_raw, labels=label_kmeans_raw, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score_without_outliers = silhouette_score(x_kmeans_outliers_removed, labels=label_kmeans_outliers_removed, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means with outliers, silhouette_score:  0.1946145329361984\n",
      "K-means without outliers, silhouette_score:  0.19850465075563548\n"
     ]
    }
   ],
   "source": [
    "print(\"K-means with outliers, silhouette_score: \", silhouette_score_with_outliers)\n",
    "print(\"K-means without outliers, silhouette_score: \", silhouette_score_without_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **davies_bouldin_score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This index signifies the average ‘similarity’ between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves. Zero is the lowest possible score. Values closer to zero indicate a better partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "davies_bouldin_score_with_outliers = davies_bouldin_score(x_kmeans_raw, labels=label_kmeans_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "davies_bouldin_score_without_outliers = davies_bouldin_score(x_kmeans_outliers_removed, labels=label_kmeans_outliers_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means with outliers, davies_bouldin_score:  1.3820489730147425\n",
      "K-means without outliers, davies_bouldin_score:  1.363087260915682\n"
     ]
    }
   ],
   "source": [
    "print(\"K-means with outliers, davies_bouldin_score: \", davies_bouldin_score_with_outliers)\n",
    "print(\"K-means without outliers, davies_bouldin_score: \", davies_bouldin_score_without_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **calinski_harabasz_score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A higher Calinski-Harabasz score relates to a model with better defined clusters. The index is the ratio of the sum of between-clusters variation and of inter-cluster variation for all cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "calinski_harabasz_score_with_outliers = calinski_harabasz_score(x_kmeans_raw, labels=label_kmeans_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "calinski_harabasz_score_without_outliers = calinski_harabasz_score(x_kmeans_outliers_removed, labels=label_kmeans_outliers_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means with outliers, calinski_harabasz_score:  1722.156857190652\n",
      "K-means without outliers, calinski_harabasz_score:  1787.9731518976866\n"
     ]
    }
   ],
   "source": [
    "print(\"K-means with outliers, calinski_harabasz_score: \", calinski_harabasz_score_with_outliers)\n",
    "print(\"K-means without outliers, calinski_harabasz_score: \", calinski_harabasz_score_without_outliers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
